{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "from process import read_test,merge,merge_c,trans_txt_to_csv,calculate_er_summary\n",
    "base_path=\"/home/user_tp/workspace/code/attack/ModelNet40-C/runs/\"\n",
    "folders_all = ['dgcnn_pct_run_1_no_fps','dgcnn_pct_run_1_no_wfps','dgcnn_pct_run_1_no_wrs','dgcnn_pct_run_1_r_rwup_fps','dgcnn_pct_run_1_r_rwup_wfps','dgcnn_pct_run_1_r_rwup_wrs',\n",
    "               'dgcnn_pct_run_1_up_or_down_fps','dgcnn_pct_run_1_up_or_down_wfps','dgcnn_pct_run_1_up_or_down_wrs',\n",
    "               'dgcnn_pointnet2_run_1_no_fps','dgcnn_pointnet2_run_1_no_wfps','dgcnn_pointnet2_run_1_no_wrs','dgcnn_pointnet2_run_1_r_rwup_fps','dgcnn_pointnet2_run_1_r_rwup_wfps',\n",
    "               'dgcnn_pointnet2_run_1_r_rwup_wrs','dgcnn_pointnet2_run_1_up_or_down_fps','dgcnn_pointnet2_run_1_up_or_down_wfps','dgcnn_pointnet2_run_1_up_or_down_wrs',\n",
    "               'cutmix_k_pct_run_1','cutmix_r_pct_run_1','mixup_pct_run_1','pgd_pct_run_1','rsmix_pct_run_1',\n",
    "               'cutmix_k_pointnet2_run_1','cutmix_r_pointnet2_run_1','mixup_pointnet2_run_1','rsmix_pointnet2_run_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timer import ProfileTimer\n",
    "from PCT_Pytorch.interpolation import Interpolation\n",
    "from PCT_Pytorch.sampling import process_point_cloud,process_point_cloud_k,process_point_cloud_ratio,process_point_cloud_upper,process_point_cloud_mix,process_point_cloud_ra,process_point_cloud_ori_score,knn,get_normal_vector\n",
    "from PCT_Pytorch.perbutation import augment_pointcloud,shuffle_pointcloud,jitter_pointcloud, translate_pointcloud, rotate_pointcloud\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "use_upsample = 'up_or_down_ratio_score_2'\n",
    "device=torch.device('cuda:2')\n",
    "xyz = torch.rand(32, 1024, 3).to(device)\n",
    "# device = points.device\n",
    "B,N,C=xyz.shape\n",
    "normal = torch.zeros_like(xyz).to(device)\n",
    "for i in range(xyz.shape[0]):\n",
    "    normal[i] = get_normal_vector(xyz[i].unsqueeze(0)).squeeze(0)\n",
    "times = [] \n",
    "timer = ProfileTimer(\"Loop Timer\")\n",
    "# timer.start()\n",
    "for i in range(100):\n",
    "    # timer.reset()  # 重置计时器  \n",
    "    start_time = time.time()  # 开始计时 \n",
    "      \n",
    "    if use_upsample=='up_or_down':\n",
    "        x = process_point_cloud(xyz, 0.03,normal)\n",
    "    ###modify for the new method,up_or_kdown\n",
    "    if use_upsample=='up_or_kdown_0.1':\n",
    "        x = process_point_cloud_k(xyz, 0.03,normal,0.1,0.75)\n",
    "    if use_upsample=='up_or_kdown_0.2':\n",
    "        x = process_point_cloud_k(xyz, 0.03,normal,0.2,0.75)\n",
    "    if use_upsample=='up_or_kdown_0.3':\n",
    "        x = process_point_cloud_k(xyz, 0.03,normal,0.3,0.5)\n",
    "    if use_upsample=='up_or_kdown_0.3_2':\n",
    "        # print(\"hello\")\n",
    "        x = process_point_cloud_upper(xyz, 0.03,normal,0.3,0.5)\n",
    "    ###上采样random_k，下采样knn\n",
    "    if use_upsample=='up_or_kdown_ratio_2':\n",
    "        x = process_point_cloud_ratio(xyz, 0.03,normal)\n",
    "    ###上采样random_k，下采样score\n",
    "    if use_upsample=='up_or_down_ratio_score_2':\n",
    "        x = process_point_cloud_mix(xyz,0.03,normal)\n",
    "    ###上采样random_k，下采样random\n",
    "    if use_upsample=='up_or_ra_ratio_2':\n",
    "        x = process_point_cloud_ra(xyz, 0.03,normal)\n",
    "    ###上采样ori，下采样score\n",
    "    if use_upsample=='oriup_or_down_ratio_score_2':\n",
    "        x = process_point_cloud_ori_score(xyz, 0.03,normal)\n",
    "    elif use_upsample=='r_oup':\n",
    "        I = Interpolation(0.03)\n",
    "        d, idx_k = knn(xyz, k=20)\n",
    "        newx = I.random_k_neighbors_shape_invariant_perturb(xyz,d, idx_k, normal)\n",
    "        x = torch.cat((xyz, newx), dim=1)\n",
    "    elif use_upsample=='half_roup':\n",
    "        if N<1024:\n",
    "            I = Interpolation(0.03)\n",
    "            d, idx_k = knn(xyz, k=20)\n",
    "            newx = I.random_k_neighbors_shape_invariant_perturb(xyz,d ,idx_k, normal)\n",
    "            num_points_to_select = int(1024-N)\n",
    "            # sampled_indices = torch.randperm(N)[:num_points_to_select]\n",
    "            x = torch.cat((xyz, newx[:, :num_points_to_select]), dim=1)\n",
    "        else:\n",
    "            x = xyz.contiguous()\n",
    "    elif use_upsample == 'median_hroup':\n",
    "        I = Interpolation(0.03)\n",
    "        distance,idx_k = knn(xyz,k=20)\n",
    "        # pts = I.random_k_neighbors_shape_invariant_perturb(xyz, None, normal)\n",
    "        def expand_point_cloud_to_1024(original_points, accumulated_points, normal,distance,idx_k):\n",
    "            if accumulated_points.shape[1] >= 1024:  \n",
    "                return accumulated_points[:,:1024,:]\n",
    "            pts_p = I.random_k_neighbors_shape_invariant_perturb(original_points, distance,idx_k, normal)   \n",
    "            pts = torch.cat((accumulated_points, pts_p), dim=1) \n",
    "            return expand_point_cloud_to_1024(original_points, pts, normal,distance,idx_k)\n",
    "        x = expand_point_cloud_to_1024(xyz.clone(),xyz.clone(),normal,distance,idx_k)\n",
    "   \n",
    "    end_time = time.time()  # 结束计时  \n",
    "    elapsed_time = end_time - start_time  # 计算耗时  \n",
    "    print(f'{i+1}:{elapsed_time}')\n",
    "    times.append(elapsed_time)  # 将耗时添加到时间数组中 \n",
    "  \n",
    "mean_time = np.mean(times)  \n",
    "std_time = np.std(times)  # 注意：这里计算的是标准差，如果需要方差请使用np.var(times)  \n",
    "  \n",
    "print(f\"Mean time: {mean_time:.6f} seconds\")  \n",
    "print(f\"Standard deviation: {std_time:.6f} seconds\")  \n",
    "  \n",
    "# 保存时间数组到.npy文件  \n",
    "np.save(\"loop_times.npy\", times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from PCT_Pytorch.sampling import weighted_random_point_sample, cal_weight,filter_random_point_sample\n",
    "from pointnet2_ops import pointnet2_utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "npoint=512\n",
    "device=torch.device('cuda:2')\n",
    "point = torch.rand(32, 1024, 3).to(device)\n",
    "times = [] \n",
    "# timer = ProfileTimer(\"Loop Timer\")\n",
    "# timer.start()\n",
    "times_weighted = []  \n",
    "times_filter = []  \n",
    "times_furthest = []  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均值: 0.18184903689793178, 标准差: 0.09545559228308799, 样本标准差: 0.095859211809701\n"
     ]
    }
   ],
   "source": [
    "import csv  \n",
    "import math  # 导入math模块以使用sqrt函数   \n",
    "numbers = []  \n",
    "count = 0  \n",
    "batch=32\n",
    "phase='train' #train test\n",
    "model='curvenet' #pointnet2 pct curvenet\n",
    "me='fps'#fps ffps re_wrs fps512 ffps512 fps_clean ffps_clean\n",
    "filename=f'/home/user_tp/workspace/code/attack/ModelNet40-C/time/cutmix/cutmix_r/train_pointnet2.csv'\n",
    "# 尝试打开文件并读取第一行（在这种情况下，整个文件只有一行）  \n",
    "with open(filename, 'r') as file:  \n",
    "    reader = csv.reader(file)  \n",
    "    for row in reader:  \n",
    "        if row:  # 确保行不为空  \n",
    "            try:  \n",
    "                # 将行中的所有元素（即逗号分隔的数字）转换为浮点数并添加到列表中  \n",
    "                numbers = [float(num) for num in row]  \n",
    "                break  # 因为整个文件只有一行，所以读取完这一行后就可以退出循环  \n",
    "            except ValueError:  # 如果转换失败（例如，如果行中包含非数字字符）  \n",
    "                print(f\"警告：文件 {filename} 包含非数字字符。\")  \n",
    "                numbers = []  # 可选：清空列表以表示没有有效数据  \n",
    "                break  # 退出循环  \n",
    "  \n",
    "# 计算统计量  \n",
    "if numbers:  \n",
    "    mean = sum(numbers) / len(numbers)  \n",
    "    variance = sum((num - mean) ** 2 for num in numbers) / len(numbers)  \n",
    "    standard_deviation = variance ** 0.5  \n",
    "    sample_variance = sum((num - mean) ** 2 for num in numbers) / (len(numbers) - 1) if len(numbers) > 1 else 0  \n",
    "    sample_standard_deviation = sample_variance ** 0.5  \n",
    "    print(f\"均值: {mean}, 标准差: {standard_deviation}, 样本标准差: {sample_standard_deviation}\")  \n",
    "else:  \n",
    "    print(\"没有足够的数据来计算统计量。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import merge_c,trans_txt_to_csv,calculate_er_summary\n",
    "###cal er\n",
    "MNC_CORRUPTIONS = [\"occlusion\", \"lidar\", \"density_inc\", \"density\", \"cutout\", \"uniform\", \"gaussian\", \"impulse\", \"upsampling\", \"background\", \"rotation\", \"shear\", \"distortion\", \"distortion_rbf\", \"distortion_rbf_inv\"]  \n",
    "PCC_CORRUPTIONS = ['scale','jitter','dropout_global','dropout_local','add_global','add_local','rotate']\n",
    "dataset='mnc'\n",
    "model_c = 'rpc1'\n",
    "output_mnc=f\"/home/user_tp/workspace/code/attack/ModelNet40-C/checkpoints/mnc/mnc-{model_c}/\"\n",
    "output_pcc=f\"/home/user_tp/workspace/code/attack/ModelNet40-C/checkpoints/pcc/pcc-{model_c}/\"\n",
    "# output_oo3dc=f\"/home/user_tp/workspace/code/attack/ModelNet40-C/runs/oo3dc/oo3dc-{model_c}/\"\n",
    "# output_omnic=f\"/home/user_tp/workspace/code/attack/ModelNet40-C/runs/omnic/omnic-{model_c}/\"\n",
    "\n",
    "\n",
    "os.makedirs(output_mnc, exist_ok=True)\n",
    "os.makedirs(output_pcc, exist_ok=True)\n",
    "# os.makedirs(output_oo3dc, exist_ok=True)\n",
    "# os.makedirs(output_omnic, exist_ok=True)\n",
    "\n",
    "\n",
    "folders_pct = ['dgcnn_pct_run_1_no_fps','dgcnn_pct_run_1_no_wfps','dgcnn_pct_run_1_no_wrs','dgcnn_pct_run_1_r_rwup_fps','dgcnn_pct_run_1_r_rwup_wfps','dgcnn_pct_run_1_r_rwup_wrs',\n",
    "               'dgcnn_pct_run_1_up_or_down_fps','dgcnn_pct_run_1_up_or_down_wfps','dgcnn_pct_run_1_up_or_down_wrs']\n",
    "folders_pn2 = ['dgcnn_pointnet2_run_1_no_fps','dgcnn_pointnet2_run_1_no_wfps','dgcnn_pointnet2_run_1_no_wrs','dgcnn_pointnet2_run_1_r_rwup_fps','dgcnn_pointnet2_run_1_r_rwup_wfps','dgcnn_pointnet2_run_1_r_rwup_wrs',\n",
    "               'dgcnn_pointnet2_run_1_up_or_down_fps','dgcnn_pointnet2_run_1_up_or_down_wfps','dgcnn_pointnet2_run_1_up_or_down_wrs']\n",
    "\n",
    "fold_pct = ['dgcnn_curvenet_run_1_up_or_down_ratio_score_2_wrs']\n",
    "fold_pointnet2 = ['dgcnn_pointnet2_run_1_up_or_down_0.1_wrs','dgcnn_pointnet2_run_1_up_or_down_0.2_wrs','dgcnn_pointnet2_run_1_up_or_kdown_0.1_wrs','dgcnn_pointnet2_run_1_up_or_kdown_0.2_wrs']\n",
    "fold_aug=['dgcnn_curvenet_run_1_no_fps','cutmix_r_curvenet_run_1_no_fps','cutmix_k_curvenet_run_1_no_fps','mixup_curvenet_run_1_no_fps','rsmix_curvenet_run_1_no_fps','pgd_curvenet_run_1_no_fps']\n",
    "fold_aug_ck =['dgcnn_pct_run_1','cutmix_r_pct_run_1','cutmix_k_pct_run_1','mixup_pct_run_1','rsmix_pct_run_1','pgd_pct_run_1']\n",
    "# fold_oo3dc=['dgcnn_pointnet_run_1_no_no','cutmix_r_pointnet_run_1_no_no','cutmix_k_pointnet_run_1_no_no','mixup_pointnet_run_1_no_no','rsmix_pointnet_run_1_no_no','pgd_pointnet_run_1_no_no',\n",
    "#         'dgcnn_gdanet_run_1_no_no','cutmix_r_gdanet_run_1_no_no','cutmix_k_gdanet_run_1_no_no','mixup_gdanet_run_1_no_no','rsmix_gdanet_run_1_no_no','pgd_gdanet_run_1_no_no'\n",
    "#         ]\n",
    "fold_c = ['dgcnn_curvenet_run_1_up_or_down_ratio_score_2_wrs','dgcnn_curvenet_run_1_up_or_down_ratio_score_2_wrs3']\n",
    "fold_uod = ['dgcnn_pct_run_1_up_or_kdown_0.1_wrs','dgcnn_pct_run_1_up_or_kdown_0.2_wrs','dgcnn_pct_run_1_up_or_kdown_0.3_wrs',\n",
    "            'dgcnn_pointnet2_run_1_up_or_kdown_0.1_wrs','dgcnn_pointnet2_run_1_up_or_kdown_0.2_wrs','dgcnn_pointnet2_run_1_up_or_kdown_0.3_wrs']\n",
    "# fold_wfps_k_r = ['dgcnn_pct_run_1_up_or_kdown_0.3_2_wrs','dgcnn_pct_run_1_up_or_kdown_ratio_2_wrs','dgcnn_pct_run_1_up_or_down_ratio_score_2_wrs',\n",
    "                #  'dgcnn_pointnet2_run_1_up_or_kdown_0.3_2_wrs','dgcnn_pointnet2_run_1_up_or_kdown_ratio_2_wrs','dgcnn_pointnet2_run_1_up_or_down_ratio_score_2_wrs']\n",
    "fold_abla = ['dgcnn_curvenet_run_1_oriup_or_down_ratio_score_2_wrs','dgcnn_curvenet_run_1_up_or_ra_ratio_2_wrs','dgcnn_curvenet_run_1_up_or_kdown_ratio_2_wrs',\n",
    "             'dgcnn_pct_run_1_oriup_or_down_ratio_score_2_wrs','dgcnn_pct_run_1_up_or_ra_ratio_2_wrs','dgcnn_pct_run_1_up_or_kdown_ratio_2_wrs']\n",
    "fold_wfps_k_r_8 = ['dgcnn_pct_run_1_up_or_down_0.1_wrs','dgcnn_pct_run_1_up_or_kdown_0.2_wrs','dgcnn_pct_run_1_up_or_kdown_0.3_wrs','dgcnn_pct_run_1_r_rwup_wrs',\n",
    "                 'dgcnn_pointnet2_run_1_up_or_down_0.1_wrs','dgcnn_pointnet2_run_1_up_or_kdown_0.2_wrs','dgcnn_pointnet2_run_1_up_or_kdown_0.3_wrs','dgcnn_pointnet2_run_1_r_rwup_wrs']\n",
    "fold_base = ['dgcnn_dgcnn_run_1','dgcnn_rscnn_run_1','dgcnn_simpleview_run_1']\n",
    "fold_rebuttal = ['dgcnn_pct_run_1_up_or_down_ratio_score_2_wrs_2','dgcnn_pct_run_1_up_or_down_ratio_score_2_wrs_5','dgcnn_pct_run_1_up_or_down_ratio_score_2_wrs',\n",
    "                 'dgcnn_pct_run_1_up_or_down_ratio_score_2_wrs_50','dgcnn_pct_run_1_up_or_down_ratio_score_2_wrs_200','dgcnn_pct_run_1_up_or_down_ratio_score_2_wrs_500']\n",
    "fold_rpc=['dgcnn_rpc_run_1_up_or_down_ratio_score_2_wrs']#,'dgcnn_rpc_run_1_WOLFMix',dgcnn_rpc_run_1_up_or_down_ratio_score_2_wrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_file_path: /home/user_tp/workspace/code/attack/ModelNet40-C/checkpoints/dgcnn_rpc_run_1_up_or_down_ratio_score_2_wrs/mnc_median_hroup_ffps_0.95_best_test.txt\n",
      "output_file: /home/user_tp/workspace/code/attack/ModelNet40-C/checkpoints/mnc/mnc-rpc1/mnc_median_hroup_ffps_0.95_best_test/dgcnn_rpc_run_1_up_or_down_ratio_score_2_wrs_median_hroup_ffps_0.95_best_test.csv\n"
     ]
    }
   ],
   "source": [
    "###为了整理实验数据\n",
    "###修改上面的model_c,pointcloudc需要修改dataset\n",
    "\n",
    "# for up in ['up_or_down_0.1','up_or_down_0.2','up_or_kdown_0.1','up_or_kdown_0.2']:\n",
    "#     for down in ['wrs']:\n",
    "###测试的时候用的方法\n",
    "if model_c=='ffps-curvenet':\n",
    "    fold=fold_pct\n",
    "elif model_c=='pct':\n",
    "    fold=folders_pct\n",
    "elif model_c=='pointnet2_down':\n",
    "    fold=fold_pointnet2\n",
    "\n",
    "elif model_c =='base-dg-rs-sv':\n",
    "    fold=fold_base\n",
    "elif model_c =='sample-abla':\n",
    "    fold=fold_abla\n",
    "elif model_c =='ours-curvenet':\n",
    "    fold=fold_c\n",
    "elif model_c=='base-da-curvenet':\n",
    "    fold = fold_aug\n",
    "elif model_c=='pct-knn':\n",
    "    fold = fold_rebuttal\n",
    "elif model_c=='rpc1':\n",
    "    fold = fold_rpc\n",
    "else:\n",
    "    fold=folders_pn2\n",
    "\n",
    "##dataset\n",
    "if dataset == 'pcc':\n",
    "    outputs = output_pcc\n",
    "    data=PCC_CORRUPTIONS\n",
    "elif dataset =='mnc':\n",
    "    outputs=output_mnc\n",
    "    data=MNC_CORRUPTIONS\n",
    "elif dataset =='oo3d':\n",
    "    outputs=output_oo3dc\n",
    "    data = PCC_CORRUPTIONS\n",
    "elif dataset =='omnic':\n",
    "    outputs=output_omnic\n",
    "    data = PCC_CORRUPTIONS\n",
    "base_path = '/home/user_tp/workspace/code/attack/ModelNet40-C/checkpoints'\n",
    "for up in ['median_hroup']:\n",
    "# for up in ['no']:\n",
    "#     for down in ['no']:\n",
    "    for down in ['ffps_0.95']:\n",
    "    # for down in ['ffps_0.95']: #'wfps_add_0.9','wfps_add_0.95','wfps']:\n",
    "        for model in ['_best_test']:\n",
    "# for up in ['no','r_rwup']:\n",
    "#     for down in ['fps','wfps','wrs']:\n",
    "            type = f\"{up}_{down}{model}\"\n",
    "            output =outputs+f'{dataset}_{type}/'\n",
    "            os.makedirs(output, exist_ok=True)\n",
    "            trans_txt_to_csv(base_path,fold,output,dataset,type)\n",
    "            calculate_er_summary(fold,output,data,type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###修改上面的model_c,pointcloudc需要修改dataset\n",
    "csv_files = []\n",
    "###\n",
    "# for up in ['half_roup1024','half_roup']:\n",
    "    # for down in ['wfps_add','wfps']:\n",
    "for up in ['median_hroup']:\n",
    "# for up in ['no']:\n",
    "    # for down in ['no']:\n",
    "    # for down in ['ffps_0.95']:\n",
    "    # for down in ['f_0.95fpsf_0.7','f_0.95fpsf_0.75','f_0.95fpsf_0.8','f_0.95fpsf_0.95','ffps_0.95']:\n",
    "    for down in ['ffps_0.5','ffps_0.55','ffps_0.6','ffps_0.65','ffps_0.7','ffps_0.75','ffps_0.8','ffps_0.85','ffps_0.9','ffps_0.95','fps']:#'wfps_add_0.9','wfps_add_0.95','wfps']:\n",
    "        for model in ['_final']:\n",
    "\n",
    "            type = f\"{up}_{down}{model}\"\n",
    "            csv_files.append(f\"{dataset}_{type}/er_{type}.csv\")\n",
    "print(csv_files)\n",
    "merge_c(csv_files,outputs,\"file_name\",\"er\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import read_test,merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###merge test\n",
    "output_test =f\"/home/user_tp/workspace/code/attack/ModelNet40-C/runs/\"\n",
    "model = 'pct'\n",
    "folder=[]\n",
    "output = output_test+f\"test-{model}-down/\"\n",
    "os.makedirs(output, exist_ok=True)\n",
    "\n",
    "for up in ['selfmix_randomts']:\n",
    "    for down in ['wrs']:\n",
    "        type = f\"{up}_{down}\"\n",
    "        folder.append(f\"dgcnn_{model}_run_1_{type}\")\n",
    "print(\"fold:\",folder)\n",
    "test_files=[]\n",
    "for up in ['no','r_rwup']:\n",
    "    for down in ['wfps']:\n",
    "        type = f\"{up}_{down}\"\n",
    "        test_files.append(f\"test-{model}-down/{type}.csv\")\n",
    "        read_test(output_test,output,folder,type,model)\n",
    "\n",
    "# print(\"test_files:\",test_files)\n",
    "# merge(test_files,output_test,\"folder\",\"acc\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "  \n",
    "def get_first_level_folders(directory):  \n",
    "    folders = []  \n",
    "    for item in os.listdir(directory):  \n",
    "        item_path = os.path.join(directory, item)  \n",
    "        if os.path.isdir(item_path):  \n",
    "            folders.append(item)  \n",
    "    return folders  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用示例  \n",
    "folder_path = '/home/user_tp/workspace/code/attack/ModelNet40-C/runs/mnc'  # 请将此路径替换为您要提取文件名的文件夹路径  \n",
    "file_names_list = get_first_level_folders(folder_path)  \n",
    "print(file_names_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    \n",
    "import matplotlib.pyplot as plt    \n",
    "from matplotlib.ticker import StrMethodFormatter  \n",
    "\n",
    "m='pcc'\n",
    "# CSV文件路径    \n",
    "file1_path = f'/home/user_tp/workspace/code/attack/ModelNet40-C/runs/{m}/{m}-ffps-pct/er.csv'    \n",
    "file2_path = f'/home/user_tp/workspace/code/attack/ModelNet40-C/runs/{m}/{m}-ffps-curvenet/er.csv'    \n",
    "    \n",
    "# 横轴数据    \n",
    "x_axis = [0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90,0.95, 1.00]    \n",
    "    \n",
    "def read_csv_data(file_path):    \n",
    "    # 读取CSV文件，跳过第一行（标题行），并假设第二行是我们需要的数据  \n",
    "    data = pd.read_csv(file_path, header=None).iloc[1, 1:]   \n",
    "    num_list = [round(float(item), 4) * 100 for item in data.astype(str)]  # 注意：这里假设data是Series  \n",
    "    return num_list    \n",
    "    \n",
    "# 读取两个CSV文件的数据    \n",
    "data1 = read_csv_data(file1_path)    \n",
    "data2 = read_csv_data(file2_path)    \n",
    "    \n",
    "# 绘制折线图    \n",
    "plt.figure(figsize=(8, 6))    \n",
    "plt.plot(x_axis, data1, label='PCT', color='red', marker='o')    \n",
    "plt.plot(x_axis, data2, label='CurveNet', color='blue', marker='o')    \n",
    "    \n",
    "# 添加图例、标题和坐标轴标签      \n",
    "# plt.title('Difference proportions of FFPS', fontsize=24)      \n",
    "plt.xlabel('Threshold $\\omega$', fontsize=24)      \n",
    "plt.ylabel('mER(%)', fontsize=24)      \n",
    "plt.legend(fontsize=28)    \n",
    "  \n",
    "# 设置Y轴刻度标签格式化为一位小数  \n",
    "plt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:.1f}'))  \n",
    "plt.tick_params(axis='both', which='major', labelsize=16)  # 同时调整x轴和y轴的主要刻度标签字体为16  \n",
    "# plt.yticks([15.0, 17.5, 20.0, 22.5, 25.0], ['15.0', '17.5', '20.0', '22.5', '25.0'])#mnc\n",
    "plt.yticks([12.5, 18.5, 24.5, 30.5, 36.5], ['12.5', '18.5', '24.5', '30.5', '36.5'])#pcc\n",
    "# 设置网格线样式  \n",
    "plt.grid(True, linestyle='--', linewidth=0.5)     \n",
    "\n",
    "# 保存图表  \n",
    "plt.savefig(f'/home/user_tp/workspace/code/attack/ModelNet40-C/visualize/ffps/{m}-ffps.png')#,format='eps',dpi=300)  \n",
    "  \n",
    "# 显示图表（如果你是在一个支持图形界面的环境中运行这段代码）  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2874, 2048, 3)\n",
      "data[0]: (2048, 3)\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "import h5py  \n",
    "\n",
    "file_path = \"/home/user_tp/workspace/data/shapenet_c/clean.h5\"  \n",
    "\n",
    "if os.path.exists(file_path):  \n",
    "    with h5py.File(file_path, 'r') as f:  \n",
    "        # 获取数据集的名称  \n",
    "        dataset_name = list(f.keys())[0]  \n",
    "        \n",
    "        # 获取数据集的 shape  \n",
    "        dataset = f[dataset_name]  \n",
    "        data_shape = dataset.shape  \n",
    "        \n",
    "        print(f\"{data_shape}\") \n",
    "        print(\"data[0]:\",dataset[0].shape) \n",
    "else:  \n",
    "    print(\"File not found.\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
